{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages (25.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in /Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages (from scikit-learn) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -U pip\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /Users/tanya/Desktop/~:coops:readmission\n",
      "pandas spec: ModuleSpec(name='pandas', loader=<_frozen_importlib_external.SourceFileLoader object at 0x10c2be1e0>, origin='/Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages/pandas/__init__.py', submodule_search_locations=['/Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages/pandas'])\n",
      "origin: /Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages/pandas/__init__.py\n",
      "search locations: ['/Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages/pandas']\n",
      "first sys.path entries: ['/Library/Frameworks/Python.framework/Versions/3.12/lib/python312.zip', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12', '/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/lib-dynload', '', '/Users/tanya/coops/readmission/.venv/lib/python3.12/site-packages']\n"
     ]
    }
   ],
   "source": [
    "import importlib.util, sys, os\n",
    "spec = importlib.util.find_spec(\"pandas\")\n",
    "print(\"cwd:\", os.getcwd())\n",
    "print(\"pandas spec:\", spec)\n",
    "print(\"origin:\", getattr(spec, \"origin\", None))\n",
    "print(\"search locations:\", getattr(spec, \"submodule_search_locations\", None))\n",
    "print(\"first sys.path entries:\", sys.path[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN ready\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "print(\"KNN ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (101766, 41)\n",
      "y shape: (101766, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>payer_code</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>...</th>\n",
       "      <th>examide</th>\n",
       "      <th>citoglipton</th>\n",
       "      <th>insulin</th>\n",
       "      <th>glyburide-metformin</th>\n",
       "      <th>glipizide-metformin</th>\n",
       "      <th>glimepiride-pioglitazone</th>\n",
       "      <th>metformin-rosiglitazone</th>\n",
       "      <th>metformin-pioglitazone</th>\n",
       "      <th>change</th>\n",
       "      <th>diabetesMed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[0-10)</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Pediatrics-Endocrinology</td>\n",
       "      <td>41</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Female</td>\n",
       "      <td>[10-20)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AfricanAmerican</td>\n",
       "      <td>Female</td>\n",
       "      <td>[20-30)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[30-40)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Up</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caucasian</td>\n",
       "      <td>Male</td>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Missing</td>\n",
       "      <td>Missing</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Steady</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Ch</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              race  gender      age  admission_type_id  \\\n",
       "0        Caucasian  Female   [0-10)                  6   \n",
       "1        Caucasian  Female  [10-20)                  1   \n",
       "2  AfricanAmerican  Female  [20-30)                  1   \n",
       "3        Caucasian    Male  [30-40)                  1   \n",
       "4        Caucasian    Male  [40-50)                  1   \n",
       "\n",
       "   discharge_disposition_id  admission_source_id  time_in_hospital payer_code  \\\n",
       "0                        25                    1                 1    Missing   \n",
       "1                         1                    7                 3    Missing   \n",
       "2                         1                    7                 2    Missing   \n",
       "3                         1                    7                 2    Missing   \n",
       "4                         1                    7                 1    Missing   \n",
       "\n",
       "          medical_specialty  num_lab_procedures  ...  examide  citoglipton  \\\n",
       "0  Pediatrics-Endocrinology                  41  ...       No           No   \n",
       "1                   Missing                  59  ...       No           No   \n",
       "2                   Missing                  11  ...       No           No   \n",
       "3                   Missing                  44  ...       No           No   \n",
       "4                   Missing                  51  ...       No           No   \n",
       "\n",
       "   insulin  glyburide-metformin  glipizide-metformin  \\\n",
       "0       No                   No                   No   \n",
       "1       Up                   No                   No   \n",
       "2       No                   No                   No   \n",
       "3       Up                   No                   No   \n",
       "4   Steady                   No                   No   \n",
       "\n",
       "   glimepiride-pioglitazone metformin-rosiglitazone metformin-pioglitazone  \\\n",
       "0                        No                      No                     No   \n",
       "1                        No                      No                     No   \n",
       "2                        No                      No                     No   \n",
       "3                        No                      No                     No   \n",
       "4                        No                      No                     No   \n",
       "\n",
       "  change diabetesMed  \n",
       "0     No          No  \n",
       "1     Ch         Yes  \n",
       "2     No         Yes  \n",
       "3     Ch         Yes  \n",
       "4     Ch         Yes  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readmit_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   readmit_30\n",
       "0           0\n",
       "1           0\n",
       "2           0\n",
       "3           0\n",
       "4           0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "X = pd.read_csv(\"data/X_discharge_v1.csv\")\n",
    "y = pd.read_csv(\"data/y_readmit30_v1.csv\")\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "display(X.head())\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "race             2273\n",
       "acetohexamide       0\n",
       "glyburide           0\n",
       "tolbutamide         0\n",
       "pioglitazone        0\n",
       "rosiglitazone       0\n",
       "acarbose            0\n",
       "miglitol            0\n",
       "troglitazone        0\n",
       "tolazamide          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X still has categorical strings (race, gender, age as bins, payer_code, medical_specialty, examide “No/Yes”, etc.). \n",
    "# KNN in scikit-learn needs all-numeric features.\n",
    "\n",
    "X.dtypes.value_counts()\n",
    "X.isna().sum().sort_values(ascending=False).head(10) # shows 10 most missing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"race\"] = X[\"race\"].fillna(\"Unknown\")\n",
    "X[\"race\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmit_30\n",
       "0    90409\n",
       "1    11357\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vec = y[\"readmit_30\"]\n",
    "y_vec.value_counts(dropna=False)\n",
    "\n",
    "\n",
    "# KNN will likely vote majority no readmission. we will focus not on accuracy, but on minimizing false alarms and predicting if someone is going to get readmitted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "101761    0\n",
       "101762    0\n",
       "101763    0\n",
       "101764    0\n",
       "101765    0\n",
       "Name: readmit_30, Length: 101766, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vec = y[\"readmit_30\"].astype(int)\n",
    "y_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race', 'gender', 'age', 'payer_code', 'medical_specialty', 'metformin',\n",
       "       'repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride',\n",
       "       'acetohexamide', 'glipizide', 'glyburide', 'tolbutamide',\n",
       "       'pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',\n",
       "       'tolazamide', 'examide', 'citoglipton', 'insulin',\n",
       "       'glyburide-metformin', 'glipizide-metformin',\n",
       "       'glimepiride-pioglitazone', 'metformin-rosiglitazone',\n",
       "       'metformin-pioglitazone', 'change', 'diabetesMed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify which cols are categorical \n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 196)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_enc = pd.get_dummies(X, columns=cat_cols, drop_first=False)\n",
    "X_enc.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>number_emergency</th>\n",
       "      <th>number_inpatient</th>\n",
       "      <th>...</th>\n",
       "      <th>glimepiride-pioglitazone_No</th>\n",
       "      <th>glimepiride-pioglitazone_Steady</th>\n",
       "      <th>metformin-rosiglitazone_No</th>\n",
       "      <th>metformin-rosiglitazone_Steady</th>\n",
       "      <th>metformin-pioglitazone_No</th>\n",
       "      <th>metformin-pioglitazone_Steady</th>\n",
       "      <th>change_Ch</th>\n",
       "      <th>change_No</th>\n",
       "      <th>diabetesMed_No</th>\n",
       "      <th>diabetesMed_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
       "0                  6                        25                    1   \n",
       "1                  1                         1                    7   \n",
       "2                  1                         1                    7   \n",
       "3                  1                         1                    7   \n",
       "4                  1                         1                    7   \n",
       "\n",
       "   time_in_hospital  num_lab_procedures  num_procedures  num_medications  \\\n",
       "0                 1                  41               0                1   \n",
       "1                 3                  59               0               18   \n",
       "2                 2                  11               5               13   \n",
       "3                 2                  44               1               16   \n",
       "4                 1                  51               0                8   \n",
       "\n",
       "   number_outpatient  number_emergency  number_inpatient  ...  \\\n",
       "0                  0                 0                 0  ...   \n",
       "1                  0                 0                 0  ...   \n",
       "2                  2                 0                 1  ...   \n",
       "3                  0                 0                 0  ...   \n",
       "4                  0                 0                 0  ...   \n",
       "\n",
       "   glimepiride-pioglitazone_No  glimepiride-pioglitazone_Steady  \\\n",
       "0                         True                            False   \n",
       "1                         True                            False   \n",
       "2                         True                            False   \n",
       "3                         True                            False   \n",
       "4                         True                            False   \n",
       "\n",
       "   metformin-rosiglitazone_No  metformin-rosiglitazone_Steady  \\\n",
       "0                        True                           False   \n",
       "1                        True                           False   \n",
       "2                        True                           False   \n",
       "3                        True                           False   \n",
       "4                        True                           False   \n",
       "\n",
       "   metformin-pioglitazone_No  metformin-pioglitazone_Steady  change_Ch  \\\n",
       "0                       True                          False      False   \n",
       "1                       True                          False       True   \n",
       "2                       True                          False      False   \n",
       "3                       True                          False       True   \n",
       "4                       True                          False       True   \n",
       "\n",
       "   change_No  diabetesMed_No  diabetesMed_Yes  \n",
       "0       True            True            False  \n",
       "1      False           False             True  \n",
       "2       True           False             True  \n",
       "3      False           False             True  \n",
       "4      False           False             True  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_AfricanAmerican</th>\n",
       "      <th>race_Asian</th>\n",
       "      <th>race_Caucasian</th>\n",
       "      <th>race_Hispanic</th>\n",
       "      <th>race_Other</th>\n",
       "      <th>race_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_AfricanAmerican  race_Asian  race_Caucasian  race_Hispanic  \\\n",
       "0                 False       False            True          False   \n",
       "1                 False       False            True          False   \n",
       "2                  True       False           False          False   \n",
       "3                 False       False            True          False   \n",
       "4                 False       False            True          False   \n",
       "\n",
       "   race_Other  race_Unknown  \n",
       "0       False         False  \n",
       "1       False         False  \n",
       "2       False         False  \n",
       "3       False         False  \n",
       "4       False         False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_enc.filter(like=\"race_\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71236, 196), (15265, 196), (15265, 196))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# “maximize precision subject to recall ≥ 70%” involves choosing a threshold, validation.\n",
    "# train: 70%\n",
    "# validation: 15%. used to decide which k is best, whether weights = distance helps, which prob threshold T gives recall > = 70.\n",
    "# test: 15% \n",
    "\n",
    "# split\n",
    "\n",
    "# 1) split off test (15%)\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X_enc, y_vec,\n",
    "    test_size=0.15,\n",
    "    random_state=42,\n",
    "    stratify= y_vec\n",
    ")\n",
    "\n",
    "# 2) split train vs val (val is 15% of total -> 0.15/0.85 of trainval)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval,\n",
    "    test_size=0.15/0.85,\n",
    "    random_state=42,\n",
    "    stratify=y_trainval\n",
    ")\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,\n",
       " 0.19097574147586624,\n",
       " [(200, 0.19097574147586624),\n",
       "  (300, 0.19097574147586624),\n",
       "  (500, 0.19097574147586624),\n",
       "  (196, 0.19097574147586624),\n",
       "  (50, 0.1908430687704581),\n",
       "  (100, 0.1904887232651531)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature filtering (TRAIN ONLY)\n",
    "\n",
    "# Mutual Information (better for non-linear but linear as well, still train-only)\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) MI ranking (train only)\n",
    "mi = mutual_info_classif(X_train, y_train, random_state=42) # mi = a 1D NumPy array of length n_features. estimates how much knowing feature X helps predict whether y=1 vs y=0.\n",
    "            # “If I know the value of this feature, does that reduce my uncertainty about y?”\n",
    "                # If the feature behaves differently for y=0 vs y=1 → informative → MI > 0\n",
    "\n",
    "# “How much knowing this feature reduces uncertainty about readmission?”\n",
    "mi = pd.Series(mi, index=X_train.columns).sort_values(ascending=False) # converts raw MI array into labeled vector. each MI score is now attached to its feature name. sorts from most informative to least. \n",
    "# a ranked list of features by usefulness.  \n",
    "# tells which number belongs to which feature name, by tracking positions\n",
    "\n",
    "K_grid = [50, 100, 200, 300, 500, X_train.shape[1]] # fixed K vs all cols.  # keeps the top K most informative features. \n",
    "w = 1 # placeholder for no weighting yet\n",
    "\n",
    "K_results = []\n",
    "\n",
    "for K in K_grid:\n",
    "    keep_cols = mi.head(K).index.tolist()\n",
    "\n",
    "    # 2) apply same columns to train/val\n",
    "    Xtr = X_train[keep_cols]\n",
    "    Xva = X_val[keep_cols]\n",
    "\n",
    "    # 3) scale (fit on train only)\n",
    "    scaler = StandardScaler()\n",
    "    Xtr_s = scaler.fit_transform(Xtr)\n",
    "    Xva_s = scaler.transform(Xva)\n",
    "\n",
    "    # 4) train + score, by PR-AUC on val, simple baseline logreg model to compare K values\n",
    "    lr = LogisticRegression(max_iter=2000, class_weight={0: 1, 1: w})\n",
    "    lr.fit(Xtr_s, y_train)\n",
    "\n",
    "    va_proba = lr.predict_proba(Xva_s)[:, 1]\n",
    "    pr = average_precision_score(y_val, va_proba)\n",
    "\n",
    "    K_results.append((K, pr))\n",
    "\n",
    "best_K, best_pr = max(K_results, key=lambda x: x[1])\n",
    "best_K, best_pr, sorted(K_results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing the smallest K for simplicity. since K=196,200,300,500 all have the same PR-AUC\n",
    "\n",
    "K = 196\n",
    "keep_cols = mi.head(K).index.tolist()\n",
    "\n",
    "X_train_f = X_train[keep_cols]\n",
    "X_val_f   = X_val[keep_cols]\n",
    "X_test_f  = X_test[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping redundant cols: 16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((71236, 180), (15265, 180), (15265, 180))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- Drop one of any pair of features with abs(corr) > threshold (TRAIN ONLY) ---\n",
    "threshold = 0.95 # if 2 features are correlated more than 0.95, they are essentially the same signal and keeping both will add noise and instability. \n",
    "\n",
    "corr = X_train_f.corr().abs() \t# computes feature–feature correlation matrix. entry (i, j) = correlation between feature i and feature j. is symmetric\n",
    "\n",
    "upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool)) # (mask) keeps values where mask is True, and makes everything else NaN.\n",
    "# Keeps only the upper triangle of the correlation matrix\n",
    "# Prevents double-counting pairs like (A,B) and (B,A)\n",
    "# Prevents comparing a feature with itself\n",
    "\n",
    "# columns to drop: any column that has correlation > threshold with something earlier\n",
    "to_drop = [col for col in upper.columns if any(upper[col] > threshold)] # Drops any feature that is highly correlated (>0.95) with any earlier feature.”\n",
    "\n",
    "print(\"Dropping redundant cols:\", len(to_drop))\n",
    "# print(to_drop[:30])  # optional peek\n",
    "\n",
    "# apply the drop to train/val/test using the SAME columns\n",
    "X_train_f = X_train_f.drop(columns=to_drop)\n",
    "X_val_f   = X_val_f.drop(columns=to_drop)\n",
    "X_test_f  = X_test_f.drop(columns=to_drop)\n",
    "\n",
    "X_train_f.shape, X_val_f.shape, X_test_f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before redundancy drop: 196\n",
      "After redundancy drop: 180\n"
     ]
    }
   ],
   "source": [
    "# to see how many columns got removed\n",
    "print(\"Before redundancy drop:\", X_train[keep_cols].shape[1])\n",
    "print(\"After redundancy drop:\", X_train_f.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit scaler on train\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train_f) # fit ONLY on train\n",
    "X_val_s   = scaler.transform(X_val_f)\n",
    "X_test_s  = scaler.transform(X_test_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w': 13,\n",
       " 'model': LogisticRegression(class_weight={0: 1, 1: 13}, max_iter=2000),\n",
       " 'pr_auc': 0.1918235303905126}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) LogReg\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "weight_grid = [1, 2, 3, 5, 8, 13]\n",
    "best = None\n",
    "\n",
    "for w in weight_grid:\n",
    "    lr = LogisticRegression(max_iter=2000, class_weight={0:1, 1:w})\n",
    "    lr.fit(X_train_s, y_train)\n",
    "\n",
    "    y_val_proba = lr.predict_proba(X_val_s)[:, 1]\n",
    "    pr_auc = average_precision_score(y_val, y_val_proba)\n",
    "\n",
    "    if (best is None) or (pr_auc > best[\"pr_auc\"]):\n",
    "        best = {\"w\": w, \"model\": lr, \"pr_auc\": pr_auc}\n",
    "\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr = best[\"model\"]   # weight = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "\n",
    "y_val_proba = best_lr.predict_proba(X_val_s)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1918235303905126, 0.6393829240157833)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_auc  = average_precision_score(y_val, y_val_proba)\n",
    "roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "pr_auc, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.5705008883338997), 0.1468685142229276, 0.7064004697592484)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the highest threshold that still gives recall ≥ 0.70 \n",
    "# (minimize false alarms while meeting the recall floor)\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "thresholds = np.linspace(y_val_proba.min(), y_val_proba.max(), 300)\n",
    "\n",
    "best_t = None\n",
    "best_prec = -1\n",
    "best_rec = None\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (y_val_proba >= t).astype(int)\n",
    "    r = recall_score(y_val, preds, zero_division=0)\n",
    "    p = precision_score(y_val, preds, zero_division=0)\n",
    "\n",
    "    if r >= 0.70 and p > best_prec:\n",
    "        best_prec = p\n",
    "        best_t = t\n",
    "        best_rec = r\n",
    "\n",
    "best_t, best_prec, best_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1468685142229276,\n",
       " 0.7064004697592484,\n",
       " np.float64(0.5365869636423191),\n",
       " (np.int64(6574), np.int64(6988), np.int64(500), np.int64(1203)))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect confusion matrix at threshold 0.5, 0.3\n",
    "\n",
    "                    #confusion matrix: \n",
    "                    # [ True Neg    False Pos\n",
    "                    #   False Neg    True pos]\n",
    "\n",
    "                    # This will answer concretely:\n",
    "                        # How many patients are flagged?\n",
    "                        # How many readmissions are missed?\n",
    "                        # Does recall reach your 70% target?\n",
    "                        # How bad do false alarms get?\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "t = float(best_t)\n",
    "pred = (y_val_proba >= t).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, pred).ravel()\n",
    "\n",
    "precision = precision_score(y_val, pred, zero_division=0)\n",
    "recall    = recall_score(y_val, pred, zero_division=0)\n",
    "flag_rate = (tp+fp)/len(y_val)\n",
    "\n",
    "precision, recall, flag_rate, (tn, fp, fn, tp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) KNN (oversampling)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def oversample_positive(X, y, pos_mult=1, seed=42):\n",
    "    if pos_mult <= 1:\n",
    "        return X, y\n",
    "    rng = np.random.default_rng(seed) # creates a random number generator using the given seed. default_rng is modern NumPy style and reproducible.\n",
    "    # “pick some positive rows at random and duplicate them.” \n",
    "    y = np.asarray(y) # makes sure y is a NumPy array\n",
    "    X = np.asarray(X) \n",
    "    pos_idx = np.where(y == 1)[0] # finds indices of all pos examples (readmitted =1). np.where returns a tuple, [0], and extracts index array.\n",
    "    if len(pos_idx) == 0:\n",
    "        return X, y\n",
    "    extra = rng.choice(pos_idx, size=(pos_mult - 1) * len(pos_idx), replace=True) # # takes number of pos, multiplies by how many extra positives u want, \n",
    "    # can pick the same positive row multiple times (replace = true means with replacement\n",
    "    X_os = np.vstack([X, X[extra]]) # x[extra] gets the resampled pos rows, and vstack stacks them under original X\n",
    "    y_os = np.concatenate([y, y[extra]]) # append extra 1s , since y[extra] are all pos\n",
    "    return X_os, y_os # oversampled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 'distance', 3001, 0.18121045497806598, 0.6214731794815797)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN tuning: \n",
    "# you try k in [3, 5, 7, 9, 15, 25, 51]\n",
    "# pick best by PR-AUC\n",
    "# save “best k” in notes\n",
    "\n",
    "# Train each KNN and score by PR-AUC on validation. MANUAL\n",
    "\n",
    "man_os_results = []\n",
    "pos_mult_grid = [1, 2, 3, 5, 8, 13]\n",
    "k_list = [11, 21, 51, 101, 201, 401, 801, 1501, 3001] \n",
    "\n",
    "for pos_mult in pos_mult_grid:\n",
    "    X_tr_os, y_tr_os = oversample_positive(X_train_s, y_train, pos_mult=pos_mult, seed=42) # for this pos mult, oversample only the training set, not val/test.\n",
    "    # X_tr_os: oversampled feature matrix (still scaled), y_tr_os: oversampled labels\n",
    "\n",
    "    for w in [\"uniform\", \"distance\"]:\n",
    "        for k in k_list:\n",
    "            knn = KNeighborsClassifier(n_neighbors=k, weights=w)\n",
    "            knn.fit(X_tr_os, y_tr_os)\n",
    "\n",
    "            man_os_val_proba = knn.predict_proba(X_val_s)[:, 1]  # predict_proba(...) returns an array of shape (n_samples, 2). [:, 1] extracts the probability of readmitted (class 1)\n",
    "            man_os_pr = average_precision_score(y_val, man_os_val_proba)\n",
    "            man_os_roc = roc_auc_score(y_val, man_os_val_proba)\n",
    "\n",
    "            man_os_results.append((pos_mult, w, k, man_os_pr, man_os_roc))\n",
    "\n",
    "# sort by PR-AUC col (index 3), descending\n",
    "man_os_best = max(man_os_results, key=lambda r: r[3]) \n",
    "man_os_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'knn__n_neighbors': 3001, 'ros__sampling_strategy': 0.2},\n",
       " np.float64(0.184244547272639))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imblearn Pipeline. Matters because it guarantees:\n",
    "\t# oversampling happens only on the training split inside CV (no leakage),\n",
    "\t# scaling + oversampling + model are treated as one unit for tuning.\n",
    "\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ros\", RandomOverSampler(random_state=42)),\n",
    "    (\"knn\", KNeighborsClassifier(weights=\"distance\"))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": [11, 21, 51, 101, 201, 401, 801, 1501, 3001],\n",
    "    \"ros__sampling_strategy\": [0.15, 0.20, 0.30, 0.40, 0.50], # target minority/majority ratio\n",
    "}\n",
    "\n",
    "# Run grid search with cross-validation\n",
    "pipe_gs = GridSearchCV(\n",
    "    pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"average_precision\",\n",
    "    cv=5, # Cross-validation = how it estimates performance for each config using only the training set. splits data into 5 folds. trains on 4 folds, evaluates on 1 held-out fold. repeat 5 times (w all folds). \n",
    "    # then avg the 5 scores\n",
    ")\n",
    "\n",
    "pipe_gs.fit(X_train, y_train)\n",
    "\n",
    "pipe_best_params = pipe_gs.best_params_\n",
    "pipe_best_score = pipe_gs.best_score_\n",
    "best_knn_pipe = pipe_gs.best_estimator_\n",
    "\n",
    "pipe_best_params, pipe_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('ros',\n",
      "                 RandomOverSampler(random_state=42, sampling_strategy=0.2)),\n",
      "                ('knn',\n",
      "                 KNeighborsClassifier(n_neighbors=3001, weights='distance'))])\n",
      "KNeighborsClassifier(n_neighbors=3001, weights='distance')\n",
      "RandomOverSampler(random_state=42, sampling_strategy=0.2)\n"
     ]
    }
   ],
   "source": [
    "print(best_knn_pipe)\n",
    "print(best_knn_pipe.named_steps[\"knn\"])\n",
    "print(best_knn_pipe.named_steps[\"ros\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing a final KNN approach\n",
    "\n",
    "# (1) Manual oversampling + manual hyperparameter search:\n",
    "#     - Oversampled the TRAIN set by duplicating positive cases (pos_mult)\n",
    "#     - Tuned (pos_mult, weights, k) using PR-AUC on the validation set\n",
    "#     - Best manual config: pos_mult=2, weights=\"distance\", k=3001\n",
    "#     - Validation PR-AUC ≈ 0.1812\n",
    "\n",
    "# (2) imblearn Pipeline + GridSearchCV (preferred):\n",
    "#     - Pipeline = StandardScaler -> RandomOverSampler -> KNN\n",
    "#     - GridSearchCV tunes k and oversampling amount using cross-validation\n",
    "#     - Oversampling is applied ONLY to training folds inside CV (prevents leakage)\n",
    "#     - Best pipeline config: k=3001, sampling_strategy=0.2, weights=\"distance\"\n",
    "#     - Mean CV PR-AUC ≈ 0.1842\n",
    "\n",
    "# Decision:\n",
    "# We use the Pipeline+CV model for the rest of the notebook because it’s the cleanest evaluation (no leakage) and gives the best PR-AUC in cross-validation.\n",
    "# Manual results are kept for comparison and justification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.17810913971890988, 0.6179632774141903)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save probabilities for threshold analysis for the validation table later (same style as logreg, using the chosen pipeline)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "val_proba_knn = best_knn_pipe.predict_proba(X_val)[:, 1]\n",
    "pr_auc_knn_val = average_precision_score(y_val, val_proba_knn)\n",
    "roc_auc_knn_val = roc_auc_score(y_val, val_proba_knn)\n",
    "\n",
    "pr_auc_knn_val, roc_auc_knn_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE KNN\n",
      "PR-AUC: 0.17810913971890988 ROC-AUC: 0.6179632774141903\n",
      "Best threshold (recall>=0.70): 0.16064548376443422 precision: 0.13665230210932183 recall: 0.7075748678802114\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "import numpy as np\n",
    "\n",
    "# --- helper: choose threshold to maximize precision subject to recall >= floor ---\n",
    "def pick_threshold(y_true, proba, recall_floor=0.70, n=300):\n",
    "    thresholds = np.linspace(proba.min(), proba.max(), n)\n",
    "    best_t, best_p, best_r = None, -1, None\n",
    "\n",
    "    for t in thresholds:\n",
    "        pred = (proba >= t).astype(int)\n",
    "        r = recall_score(y_true, pred, zero_division=0)\n",
    "        p = precision_score(y_true, pred, zero_division=0)\n",
    "\n",
    "        if r >= recall_floor and p > best_p:\n",
    "            best_p, best_t, best_r = p, t, r\n",
    "\n",
    "    return best_t, best_p, best_r\n",
    "\n",
    "# (A) PIPELINE KNN (your chosen one)\n",
    "pipe_val_proba = best_knn_pipe.predict_proba(X_val)[:, 1]\n",
    "pipe_pr_auc = average_precision_score(y_val, pipe_val_proba)\n",
    "pipe_roc_auc = roc_auc_score(y_val, pipe_val_proba)\n",
    "\n",
    "pipe_t, pipe_prec, pipe_rec = pick_threshold(y_val, pipe_val_proba, recall_floor=0.70)\n",
    "\n",
    "print(\"PIPELINE KNN\")\n",
    "print(\"PR-AUC:\", pipe_pr_auc, \"ROC-AUC:\", pipe_roc_auc)\n",
    "print(\"Best threshold (recall>=0.70):\", pipe_t, \"precision:\", pipe_prec, \"recall:\", pipe_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((np.int64(5949), np.int64(7613), np.int64(498), np.int64(1205)),\n",
       " 0.13665230210932183,\n",
       " 0.7075748678802114,\n",
       " np.float64(0.5776613167376351))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN: confusion matrix, precision score, recall score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "pred_knn = (pipe_val_proba >= pipe_t).astype(int)\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, pred_knn).ravel()\n",
    "\n",
    "prec = precision_score(y_val, pred_knn, zero_division=0)\n",
    "rec  = recall_score(y_val, pred_knn, zero_division=0)\n",
    "flag_rate = (tp + fp) / len(y_val)\n",
    "\n",
    "(tn, fp, fn, tp), prec, rec, flag_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - Logistic Regression has higher PR-AUC on validation (better ranking of readmissions).\n",
    "# - KNN (even with oversampling + distance weights) did not outperform LogReg on PR-AUC here.\n",
    "# - KNN thresholding to hit recall ≥ 0.70 requires flagging a large fraction of patients (high false-alarm rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) SVM (Supporting Vector Machine)\n",
    "\n",
    "# We will do LinearSVC to get decision score, and then calibrate to probabilities. SVC(probability=True)  is too slow\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01,\n",
       " 'w': 1,\n",
       " 'model': CalibratedClassifierCV(cv=5,\n",
       "                        estimator=LinearSVC(C=0.01, class_weight={0: 1, 1: 1},\n",
       "                                            max_iter=20000)),\n",
       " 'pr_auc': 0.19294614212081912,\n",
       " 'roc_auc': 0.6405925662036417}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tune on validation PR-AUC\n",
    "\n",
    "C_grid = [0.01, 0.1, 1, 3, 10] # C controls regularization strength.\n",
    "\t\t# Smaller C → stronger regularization → simpler boundary (more bias, less variance)\n",
    "\t\t# Larger C → weaker regularization → fits training data harder\n",
    "pos_w_grid = [1, 2, 3, 5, 8, 13]   # same idea as the logreg weight grid. ex: Higher weight makes misclassifying a positive cost more in training.\n",
    "\n",
    "best_svm = None\n",
    "\n",
    "for C in C_grid:\n",
    "    for w in pos_w_grid:\n",
    "        base = LinearSVC(C=C, class_weight={0: 1, 1: w}, max_iter=20000)\n",
    "        \n",
    "        # calibrate to get probabilities (Platt scaling)\n",
    "        svm = CalibratedClassifierCV(base, method=\"sigmoid\", cv=5)\n",
    "        svm.fit(X_train_s, y_train)\n",
    "\n",
    "        val_proba = svm.predict_proba(X_val_s)[:, 1]\n",
    "        pr = average_precision_score(y_val, val_proba)\n",
    "        roc = roc_auc_score(y_val, val_proba)\n",
    "\n",
    "        if (best_svm is None) or (pr > best_svm[\"pr_auc\"]):\n",
    "            best_svm = {\"C\": C, \"w\": w, \"model\": svm, \"pr_auc\": pr, \"roc_auc\": roc}\n",
    "\n",
    "best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.09), 0.13975089719231581, 0.7774515560775103)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# threshold \n",
    "\n",
    "best_svm_model = best_svm[\"model\"]\n",
    "svm_val_proba = best_svm_model.predict_proba(X_val_s)[:, 1]\n",
    "\n",
    "thresholds = np.linspace(0.05, 0.95, 91)\n",
    "\n",
    "best_t_svm = None\n",
    "best_prec_svm = -1\n",
    "best_rec_svm = None\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (svm_val_proba >= t).astype(int)\n",
    "    r = recall_score(y_val, preds, zero_division=0)\n",
    "    p = precision_score(y_val, preds, zero_division=0)\n",
    "    if r >= 0.70 and p > best_prec_svm:\n",
    "        best_prec_svm = p\n",
    "        best_t_svm = t\n",
    "        best_rec_svm = r\n",
    "\n",
    "best_t_svm, best_prec_svm, best_rec_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Model Comparison Summary (for validation)\n",
    "\n",
    "# Logistic Regression provides a strong and interpretable baseline.\n",
    "# KNN underperforms Logistic Regression despite oversampling and tuning.\n",
    "# Calibrated Linear SVM achieves the highest PR-AUC and ROC-AUC.\n",
    "# Under a recall ≥ 70% constraint, SVM offers the best tradeoff between recall and precision.\n",
    "\n",
    "\n",
    "# Conclusion:\n",
    "# We proceed with the calibrated SVM for downstream analysis, as it best balances recall and ranking performance under class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING ALL 3 \n",
    "\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    confusion_matrix, precision_score, recall_score\n",
    ")\n",
    "\n",
    "def eval_on_test(y_true, proba, t):\n",
    "    t = float(t)\n",
    "    pred = (proba >= t).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel()\n",
    "\n",
    "    return {\n",
    "        \"ROC_AUC\": float(roc_auc_score(y_true, proba)),\n",
    "        \"PR_AUC\": float(average_precision_score(y_true, proba)),\n",
    "        \"threshold\": t,\n",
    "        \"precision\": float(precision_score(y_true, pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, pred, zero_division=0)),\n",
    "        \"flag_rate\": float((tp + fp) / len(y_true)),\n",
    "        \"cm\": (int(tn), int(fp), int(fn), int(tp)),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC_AUC': 0.6447495718355558,\n",
       " 'PR_AUC': 0.19951418158480766,\n",
       " 'threshold': 0.5705008883338997,\n",
       " 'precision': 0.14761498109064292,\n",
       " 'recall': 0.710093896713615,\n",
       " 'flag_rate': 0.5369800196528005,\n",
       " 'cm': (6574, 6987, 494, 1210)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Logistic regression on test (using the selected model + selected threshold)\n",
    "\n",
    "t_lr = best_t  # chosen on validation using best_lr\n",
    "y_test_proba_lr = best_lr.predict_proba(X_test_s)[:, 1]\n",
    "eval_lr = eval_on_test(y_test, y_test_proba_lr, t_lr)\n",
    "eval_lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC_AUC': 0.6214697854555993,\n",
       " 'PR_AUC': 0.18434197842480576,\n",
       " 'threshold': 0.16064548376443422,\n",
       " 'precision': 0.13886990202779675,\n",
       " 'recall': 0.7153755868544601,\n",
       " 'flag_rate': 0.5750409433344251,\n",
       " 'cm': (6002, 7559, 485, 1219)}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN on test (with best k)\n",
    "\n",
    "t_knn = 0.1087035175879397  # val-chosen threshold\n",
    "best_k = 1501  \n",
    "\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_k, weights=\"distance\")\n",
    "knn_best.fit(X_train_s, y_train)\n",
    "\n",
    "test_proba_knn = best_knn_pipe.predict_proba(X_test)[:, 1]\n",
    "eval_knn = eval_on_test(y_test, test_proba_knn, pipe_t)\n",
    "eval_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ROC_AUC': 0.6450336299932179,\n",
       " 'PR_AUC': 0.20052394468911977,\n",
       " 'threshold': 0.09,\n",
       " 'precision': 0.13962065331928344,\n",
       " 'recall': 0.7775821596244131,\n",
       " 'flag_rate': 0.6216835899115624,\n",
       " 'cm': (5396, 8165, 379, 1325)}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM on test\n",
    "\n",
    "svm_test_proba = best_svm_model.predict_proba(X_test_s)[:, 1]\n",
    "eval_svm = eval_on_test(y_test, svm_test_proba, best_t_svm)\n",
    "eval_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPRETATION OF MODEL RESULTS (TEST SET)\n",
    "\n",
    "# Metrics reported:\n",
    "#   - PR-AUC: how well the model ranks true readmissions above non-readmissions\n",
    "#             (most important metric under class imbalance)\n",
    "#   - ROC-AUC: general separability (less informative under heavy imbalance)\n",
    "#   - Precision: among flagged patients, how many are truly readmitted\n",
    "#   - Recall: fraction of all readmissions that are successfully flagged\n",
    "#   - Flag rate: fraction of the population flagged as high-risk\n",
    "\n",
    "        # LOGISTIC REGRESSION\n",
    "                # PR-AUC ≈ 0.199\n",
    "                # Recall ≈ 0.71\n",
    "                # Precision ≈ 0.148\n",
    "                # Flag rate ≈ 54%\n",
    "\n",
    "                        # Best precision among the three models under recall ≥ 70%\n",
    "                        # More conservative: fewer total alerts than KNN or SVM\n",
    "                        # Slightly weaker ranking performance than SVM (lower PR-AUC)\n",
    "\n",
    "        # KNN (PIPELINE + OVERSAMPLING)\n",
    "                # PR-AUC ≈ 0.184\n",
    "                # Recall ≈ 0.72\n",
    "                # Precision ≈ 0.139\n",
    "                # Flag rate ≈ 58%\n",
    "\n",
    "                        # Worst overall performance\n",
    "                        # Lower PR-AUC and ROC-AUC than both logistic regression and SVM\n",
    "                        # Requires flagging more patients to achieve similar recall\n",
    "                        # Dominated by the other two models\n",
    "\n",
    "        # SVM (CALIBRATED)\n",
    "                # PR-AUC ≈ 0.201  (BEST)\n",
    "                # Recall ≈ 0.78   (BEST)\n",
    "                # Precision ≈ 0.140\n",
    "                # Flag rate ≈ 62%\n",
    "\n",
    "                        # Best PR-AUC → strongest ranking of high-risk patients\n",
    "                        # Highest recall → catches the most readmissions\n",
    "                        # More aggressive: flags the largest fraction of patients\n",
    "                        # Precision slightly lower than logistic regression, but comparable\n",
    "\n",
    "# OVERALL CONCLUSIONS\n",
    "# - KNN performs worst and is not competitive.\n",
    "# - Logistic regression provides the best precision under a recall constraint.\n",
    "# - SVM achieves the best PR-AUC and highest recall, at the cost of more alerts.\n",
    "\n",
    "        # Model choice depends on operational priorities:\n",
    "\n",
    "        # If minimizing missed readmissions is critical → SVM is preferred.\n",
    "                # SVM has the best PR-AUC (ranking quality) on validation and test, so it's our primary model for downstream risk-score analyses (e.g., subgroup comparisons of predicted risk).\n",
    "\n",
    "        # If controlling alert volume / false positives is critical → logistic regression.\n",
    "                # Logistic regression is extremely close in PR-AUC and has a lower flag rate at the recall>=0.70 operating point, so we report it as a sensitivity check for decision/alert-based conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   threshold  precision    recall        F1  flagged_n  flag_rate     TN  \\\n",
       " 0        0.2   0.111637  0.996477  0.200781      15201   0.995807     58   \n",
       " 1        0.5   0.125866  0.896066  0.220728      12124   0.794235   2964   \n",
       " 2        0.8   0.302256  0.118027  0.169764        665   0.043564  13098   \n",
       " \n",
       "       FP    FN    TP  \n",
       " 0  13504     6  1697  \n",
       " 1  10598   177  1526  \n",
       " 2    464  1502   201  ,\n",
       "    threshold  precision    recall        F1  flagged_n  flag_rate     TN  \\\n",
       " 0       0.10   0.111562  1.000000  0.200731      15265   1.000000      0   \n",
       " 1       0.15   0.126819  0.874927  0.221528      11749   0.769669   3303   \n",
       " 2       0.20   0.237179  0.152085  0.185331       1092   0.071536  12729   \n",
       " \n",
       "       FP    FN    TP  \n",
       " 0  13562     0  1703  \n",
       " 1  10259   213  1490  \n",
       " 2    833  1444   259  ,\n",
       "    threshold  precision    recall        F1  flagged_n  flag_rate     TN   FP  \\\n",
       " 0        0.2   0.290713  0.126835  0.176615        743   0.048673  13035  527   \n",
       " 1        0.5   0.420000  0.012331  0.023959         50   0.003275  13533   29   \n",
       " 2        0.8   0.250000  0.000587  0.001172          4   0.000262  13559    3   \n",
       " \n",
       "      FN   TP  \n",
       " 0  1487  216  \n",
       " 1  1682   21  \n",
       " 2  1702    1  )"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold table(validation table)\n",
    "    # ( summary table that shows what happens when you change the decision cutoff used to turn predicted probabilities into yes/no decisions )\n",
    "            # Explaining tradeoffs\n",
    "            # Creating interpretable decision analysis\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def threshold_table(y_true, proba, thresholds=(0.2, 0.5, 0.8)):\n",
    "    rows = [] #  one row of the final table (store one dictionary per threshold)\n",
    "    n = len(y_true) # number of patients in this split, used for flag_rate.\n",
    "\n",
    "    for t in thresholds:\n",
    "        pred = (proba >= t).astype(int) # if p >=t , predict 1 (high risk), flag it\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, pred).ravel() # ravel() flattens the 2x2 matrix into a 1D list so you can unpack it.\n",
    "\n",
    "        prec = precision_score(y_true, pred, zero_division=0)\n",
    "        rec  = recall_score(y_true, pred)\n",
    "        f1   = f1_score(y_true, pred, zero_division=0) # F1: harmonic mean of precision and recall (single-number tradeoff summary)\n",
    "        # zero_division=0 : prevents errors when the model predicts zero positives (common at high thresholds).\n",
    "\n",
    "\n",
    "        flagged = tp + fp\n",
    "        rows.append({\n",
    "            \"threshold\": t,\n",
    "            \"precision\": prec,\n",
    "            \"recall\": rec,\n",
    "            \"F1\": f1,\n",
    "            \"flagged_n\": flagged,\n",
    "            \"flag_rate\": flagged / n,\n",
    "            \"TN\": tn, \"FP\": fp, \"FN\": fn, \"TP\": tp\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows) # After looping through thresholds and appending each row into rows, it turns it into a DataFrame.\n",
    "        # (Exact columns depend on what you added to rows.)\n",
    "\n",
    "# Validation tables\n",
    "lr_table_val  = threshold_table(y_val, y_val_proba, thresholds=(0.2, 0.5, 0.8))\n",
    "svm_table_val = threshold_table(y_val, svm_val_proba, thresholds=(0.2, 0.5, 0.8))\n",
    "\n",
    "# For KNN, consider using thresholds that are in-range for its probabilities\n",
    "knn_table_val = threshold_table(y_val, val_proba_knn, thresholds=(0.1, 0.15, 0.2))\n",
    "\n",
    "lr_table_val, knn_table_val, svm_table_val,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   threshold  precision    recall        F1  flagged_n  flag_rate     TN  \\\n",
       " 0        0.2   0.111842  0.998239  0.201147      15209   0.996331     53   \n",
       " 1        0.5   0.126444  0.899061  0.221708      12116   0.793711   2977   \n",
       " 2        0.8   0.304897  0.113263  0.165169        633   0.041467  13121   \n",
       " \n",
       "       FP    FN    TP  \n",
       " 0  13508     3  1701  \n",
       " 1  10584   172  1532  \n",
       " 2    440  1511   193  ,\n",
       "    threshold  precision    recall        F1  flagged_n  flag_rate     TN   FP  \\\n",
       " 0        0.2   0.293371  0.122066  0.172400        709   0.046446  13060  501   \n",
       " 1        0.5   0.469388  0.013498  0.026241         49   0.003210  13535   26   \n",
       " 2        0.8   0.666667  0.001174  0.002343          3   0.000197  13560    1   \n",
       " \n",
       "      FN   TP  \n",
       " 0  1496  208  \n",
       " 1  1681   23  \n",
       " 2  1702    2  ,\n",
       "    threshold  precision    recall        F1  flagged_n  flag_rate     TN  \\\n",
       " 0       0.10   0.111643  1.000000  0.200860      15263   0.999869      2   \n",
       " 1       0.15   0.124585  0.858568  0.217595      11743   0.769276   3281   \n",
       " 2       0.20   0.233271  0.147300  0.180576       1076   0.070488  12736   \n",
       " \n",
       "       FP    FN    TP  \n",
       " 0  13559     0  1704  \n",
       " 1  10280   241  1463  \n",
       " 2    825  1453   251  )"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold table (test set) \n",
    "# Apply the SAME thresholds (0.2, 0.5, 0.8 or your chosen ones) to the TEST set and report them.\n",
    "\n",
    "# If we actually deploy this model, what happens? Does the story I told myself on validation survive contact with reality?\n",
    "# Specifically:\n",
    "\t# How many patients are flagged\n",
    "\t# How many true readmissions we catch\n",
    "\t# How many false alarms we create\n",
    "\t# Whether the model is usable in practice\n",
    "\n",
    "# Test probabilities\n",
    "y_test_proba_lr  = best_lr.predict_proba(X_test_s)[:, 1]        \n",
    "y_test_proba_svm = best_svm_model.predict_proba(X_test_s)[:, 1]\n",
    "y_test_proba_knn = best_knn_pipe.predict_proba(X_test)[:, 1] \n",
    "\n",
    "# Threshold tables on TEST\n",
    "lr_table_test  = threshold_table(y_test, y_test_proba_lr,  thresholds=(0.2, 0.5, 0.8))\n",
    "svm_table_test = threshold_table(y_test, y_test_proba_svm, thresholds=(0.2, 0.5, 0.8))\n",
    "knn_table_test = threshold_table(y_test, y_test_proba_knn, thresholds=(0.1, 0.15, 0.2))\n",
    "\n",
    "lr_table_test, svm_table_test, knn_table_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPRETATION & MODEL COMPARISON (Validation + Test)\n",
    "\n",
    "# 1) Generalization check\n",
    "        # The behavior of all three models is consistent between\n",
    "        # validation and test sets.\n",
    "            # This is a very good sign:\n",
    "            #   - No major distribution shift\n",
    "            #   - No obvious overfitting\n",
    "            #   - Threshold-based conclusions remain valid on unseen data\n",
    "\n",
    "\n",
    "# 2) Logistic Regression\n",
    "        # Similar recall, precision, and flag rates\n",
    "        # Smooth, predictable tradeoff as threshold changes\n",
    "\n",
    "        #   Probabilities are well-behaved and interpretable\n",
    "        #   Operationally stable: small threshold changes do not\n",
    "        #   cause extreme swings in behavior\n",
    "\n",
    "        # Strengths:\n",
    "        #   Best precision among the models\n",
    "        #   Most predictable alert volume\n",
    "        #   Easiest to explain and justify in practice\n",
    "        # Weakness:\n",
    "        #   - Slightly worse PR-AUC than SVM (ranking power is lower)\n",
    "\n",
    "# 3) KNN\n",
    "        #   Probability mass compressed near zero\n",
    "        #   Extreme sensitivity to small threshold changes\n",
    "        #   Either flags almost everyone or almost no one\n",
    "\n",
    "        #   KNN probabilities are poorly calibrated\n",
    "        #   Model is unstable for decision-making\n",
    "        #   Threshold selection is brittle\n",
    "\n",
    "        #   KNN underperforms both Logistic Regression and SVM\n",
    "        #   Not suitable for deployment or downstream analysis\n",
    "\n",
    "\n",
    "# 4) SVM (Calibrated Linear SVM)\n",
    "        #   - Highest PR-AUC (best ranking of high-risk patients)\n",
    "        #   - Highest recall at the tuned threshold\n",
    "\n",
    "        # Strengths:\n",
    "        #   SVM is best at ordering patients by readmission risk\n",
    "        #   Under a recall ≥ 70% constraint, SVM dominates in recall\n",
    "\n",
    "        # Weaknesses:\n",
    "        #   High alert volume (~60% of patients flagged)\n",
    "        #   Precision remains low (~14%)\n",
    "\n",
    "        #   Strong model for risk ranking\n",
    "        #   Requires organizational capacity to handle many alerts\n",
    "        #   Threshold choice must be justified carefully\n",
    "\n",
    "\n",
    "# 5) Summary Comparison\n",
    "\n",
    "# Ranking performance (PR-AUC):\n",
    "#   ✔ SVM is best\n",
    "#   ✔ Logistic Regression is close\n",
    "#   ✖ KNN is worst\n",
    "\n",
    "# Recall (catching readmissions):\n",
    "#   ✔ SVM is best\n",
    "#   ✔ Logistic Regression is strong\n",
    "#   ✖ KNN unreliable\n",
    "\n",
    "# Precision (avoiding false alarms):\n",
    "#   ✔ Logistic Regression is best\n",
    "#   ✖ SVM generates more false positives\n",
    "#   ✖ KNN unstable\n",
    "\n",
    "# Operational usability:\n",
    "#   ✔ Logistic Regression is predictable and explainable\n",
    "#   ⚠ SVM requires careful thresholding and resource buy-in\n",
    "#   ✖ KNN is not deployment-safe\n",
    "\n",
    "\n",
    "# 6) Final takeaway\n",
    "# If the objective is PURE RISK RANKING under class imbalance:\n",
    "      # SVM is the strongest model (highest PR-AUC).\n",
    "\n",
    "# If the objective is OPERATIONAL DEPLOYMENT with controlled alert volume and interpretability:\n",
    "     # Logistic Regression is the safer choice.\n",
    "\n",
    "# KNN should not be used for downstream analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgroup (age-band) performance check: “does the model work similarly across ages?”\n",
    "# We will choose SVM for this, since subgroup analysis focuses on relative performance consistency (i.e., whether risk ranking degrades for certain age groups), rather than absolute alert volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['admission_type_id', 'discharge_disposition_id', 'admission_source_id',\n",
       "       'time_in_hospital', 'num_lab_procedures', 'num_procedures',\n",
       "       'num_medications', 'number_outpatient', 'number_emergency',\n",
       "       'number_inpatient',\n",
       "       ...\n",
       "       'glimepiride-pioglitazone_No', 'glimepiride-pioglitazone_Steady',\n",
       "       'metformin-rosiglitazone_No', 'metformin-rosiglitazone_Steady',\n",
       "       'metformin-pioglitazone_No', 'metformin-pioglitazone_Steady',\n",
       "       'change_Ch', 'change_No', 'diabetesMed_No', 'diabetesMed_Yes'],\n",
       "      dtype='object', length=196)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.frame.DataFrame, (15265, 196))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test), getattr(X_test, \"shape\", None) # get the attribute .shape from X_test. If it doesn’t exist, return None instead of crashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0-10)        29\n",
       "[10-20)       99\n",
       "[20-30)      254\n",
       "[30-40)      543\n",
       "[40-50)     1438\n",
       "[50-60)     2590\n",
       "[60-70)     3423\n",
       "[70-80)     3889\n",
       "[80-90)     2561\n",
       "[90-100)     439\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One table: metrics by age band (on test set)\n",
    "\n",
    "# need age_test aligned with y_test. \n",
    "# age_test: \"for each patient row, know their age group. then, can assign to a subgroup\"\n",
    "\n",
    "age_cols = [c for c in X_test.columns if \"age\" in c.lower()] # “Find all columns whose names indicate they represent age bands.” (ex: x_test has age_[60-70) = 1, others=0)\n",
    "                # c.lower makes it all lowercase so \"age\" is easy to locate\n",
    "\n",
    "age_band_test = X_test[age_cols].idxmax(axis=1)  # axis=1 = operate across columns for each row. idxmax gives col name where value is largest, =1 (1>0)\n",
    "# so each patient gets an age group label.\n",
    "\n",
    "age_band_test = age_band_test.str.replace(\"age_\", \"\", regex=False) # age gets removed, get only the group\n",
    "\n",
    "age_band_test.value_counts().sort_index() # counts how many patients in each group. sort index will sort outputs by the group label ( the index)\n",
    "# gives a length = len(X_test) vector, aligned row-for-row with X_test, y_test, and your test probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_band</th>\n",
       "      <th>n</th>\n",
       "      <th>pos</th>\n",
       "      <th>pos_rate</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>PR_AUC</th>\n",
       "      <th>flag_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0-10)</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[10-20)</td>\n",
       "      <td>99</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.826389</td>\n",
       "      <td>0.110714</td>\n",
       "      <td>0.191919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[20-30)</td>\n",
       "      <td>254</td>\n",
       "      <td>34</td>\n",
       "      <td>0.133858</td>\n",
       "      <td>0.182353</td>\n",
       "      <td>0.911765</td>\n",
       "      <td>0.791845</td>\n",
       "      <td>0.467288</td>\n",
       "      <td>0.669291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[30-40)</td>\n",
       "      <td>543</td>\n",
       "      <td>65</td>\n",
       "      <td>0.119705</td>\n",
       "      <td>0.177632</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.724332</td>\n",
       "      <td>0.284285</td>\n",
       "      <td>0.559853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[40-50)</td>\n",
       "      <td>1438</td>\n",
       "      <td>146</td>\n",
       "      <td>0.101530</td>\n",
       "      <td>0.148005</td>\n",
       "      <td>0.787671</td>\n",
       "      <td>0.715891</td>\n",
       "      <td>0.249005</td>\n",
       "      <td>0.540334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[50-60)</td>\n",
       "      <td>2590</td>\n",
       "      <td>221</td>\n",
       "      <td>0.085328</td>\n",
       "      <td>0.126841</td>\n",
       "      <td>0.701357</td>\n",
       "      <td>0.675841</td>\n",
       "      <td>0.197612</td>\n",
       "      <td>0.471815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[60-70)</td>\n",
       "      <td>3423</td>\n",
       "      <td>394</td>\n",
       "      <td>0.115104</td>\n",
       "      <td>0.138380</td>\n",
       "      <td>0.728426</td>\n",
       "      <td>0.613534</td>\n",
       "      <td>0.178068</td>\n",
       "      <td>0.605901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[70-80)</td>\n",
       "      <td>3889</td>\n",
       "      <td>476</td>\n",
       "      <td>0.122397</td>\n",
       "      <td>0.139613</td>\n",
       "      <td>0.787815</td>\n",
       "      <td>0.613336</td>\n",
       "      <td>0.193231</td>\n",
       "      <td>0.690666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[80-90)</td>\n",
       "      <td>2561</td>\n",
       "      <td>306</td>\n",
       "      <td>0.119485</td>\n",
       "      <td>0.134381</td>\n",
       "      <td>0.866013</td>\n",
       "      <td>0.606191</td>\n",
       "      <td>0.182421</td>\n",
       "      <td>0.770012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[90-100)</td>\n",
       "      <td>439</td>\n",
       "      <td>59</td>\n",
       "      <td>0.134396</td>\n",
       "      <td>0.158491</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.576539</td>\n",
       "      <td>0.173297</td>\n",
       "      <td>0.603645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_band     n  pos  pos_rate  precision    recall   ROC_AUC    PR_AUC  \\\n",
       "0    [0-10)    29    0  0.000000   0.000000  0.000000       NaN       NaN   \n",
       "1   [10-20)    99    3  0.030303   0.052632  0.333333  0.826389  0.110714   \n",
       "2   [20-30)   254   34  0.133858   0.182353  0.911765  0.791845  0.467288   \n",
       "3   [30-40)   543   65  0.119705   0.177632  0.830769  0.724332  0.284285   \n",
       "4   [40-50)  1438  146  0.101530   0.148005  0.787671  0.715891  0.249005   \n",
       "5   [50-60)  2590  221  0.085328   0.126841  0.701357  0.675841  0.197612   \n",
       "6   [60-70)  3423  394  0.115104   0.138380  0.728426  0.613534  0.178068   \n",
       "7   [70-80)  3889  476  0.122397   0.139613  0.787815  0.613336  0.193231   \n",
       "8   [80-90)  2561  306  0.119485   0.134381  0.866013  0.606191  0.182421   \n",
       "9  [90-100)   439   59  0.134396   0.158491  0.711864  0.576539  0.173297   \n",
       "\n",
       "   flag_rate  \n",
       "0   0.034483  \n",
       "1   0.191919  \n",
       "2   0.669291  \n",
       "3   0.559853  \n",
       "4   0.540334  \n",
       "5   0.471815  \n",
       "6   0.605901  \n",
       "7   0.690666  \n",
       "8   0.770012  \n",
       "9   0.603645  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SUBGROUP METRICS BY AGE BAND (SVM on TEST)\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, average_precision_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use the SAME threshold chosen on validation for SVM\n",
    "t_svm = float(best_t_svm)\n",
    "\n",
    "# predicted labels at that threshold\n",
    "pred_svm = (svm_test_proba >= t_svm).astype(int)\n",
    "\n",
    "rows = []\n",
    "for band in sorted(age_band_test.unique()):\n",
    "    idx = (age_band_test == band).values # mask: to select only rows in this band\n",
    "\n",
    "    yt = y_test[idx]               # true labels in this age band\n",
    "    yp = pred_svm[idx]             # predicted 0/1 in this age band\n",
    "    ys = svm_test_proba[idx]       # predicted probabilities in this age band\n",
    "\n",
    "    n = idx.sum() # subgroup size, how many true values in the mask \n",
    "    pos = int(yt.sum()) # how many positive (readms) in that subgroup\n",
    "\n",
    "    # ROC-AUC needs both classes present; PR-AUC needs at least 1 positive\n",
    "    roc = roc_auc_score(yt, ys) if len(np.unique(yt)) == 2 else np.nan # need at least one 0 and one 1 in the subgroup.  roc is the rate of how well you distinguish positive vs neg\n",
    "                                                                    # “do positives tend to get higher scores than negatives?”\n",
    "    pr  = average_precision_score(yt, ys) if pos > 0 else np.nan # pr is the measure of precision with recall, so you need to have a recall (a pos)\n",
    "                                                            # “when I take the highest-scored patients first, how good is precision/recall as I move down the list?”\n",
    "    rows.append({\n",
    "        \"age_band\": band,\n",
    "        \"n\": n,\n",
    "        \"pos\": pos,\n",
    "        \"pos_rate\": pos / n if n > 0 else np.nan,\n",
    "        \"precision\": precision_score(yt, yp, zero_division=0),\n",
    "        \"recall\": recall_score(yt, yp, zero_division=0),\n",
    "        \"ROC_AUC\": roc,\n",
    "        \"PR_AUC\": pr,\n",
    "        \"flag_rate\": float(yp.mean())\n",
    "    })\n",
    "\n",
    "age_metrics_svm = pd.DataFrame(rows).sort_values(\"age_band\") # \tTurn list-of-dicts (rows of labeled bundles) into a DataFrame. Each dict becomes one row. Keys become column names.\n",
    "age_metrics_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  chart: same metrics by age band\n",
    "\n",
    "# Chart 1: x=age_band, y=precision and recall (two lines or grouped bars)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plot_df = age_metrics_svm.sort_values(\"age_band\").set_index(\"age_band\")\n",
    "\n",
    "ax = plot_df[[\"precision\", \"recall\"]].plot(marker=\"o\")  # two lines\n",
    "plt.title(\"Precision and Recall by Age Group (SVM, test)\")\n",
    "plt.xlabel(\"Age group\")\n",
    "plt.ylabel(\"Rate\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERPRETATIONS\n",
    "\n",
    "# To answer the question \"If we apply the same SVM threshold to every age group, does performance stay similar?\", we can look at the table above.\n",
    "        # For threshold-based metrics (precision, recall, flag rate), it depends on t_svm.\n",
    "        # For ranking metrics (ROC-AUC, PR-AUC), it does not depend on the chosen threshold. \n",
    "\n",
    "# The test set is dominated by older groups. The youngest groups have small n values, so the metrics will be noisy. For instance, \n",
    "    # 0-10 has 0 positives, so ROC-AUC and PR-AUC cannot be computed. \n",
    "    # 10-20 has small n and small positives\n",
    "\n",
    "# We have low precision everywhere, and it ranges rougly from 0.13-0.18 for the larger groups. Most alerts are false positive, \n",
    "    # Class imbalance explains why precision is low overall, but threshold choice controls how many you flag, \n",
    "    # which directly affects precision/recall/flag_rate.\n",
    "\n",
    "# Recall varies by the age groups, thus is not equally sensitive across ages under t_svm.\n",
    "    # It is very high in [20-30] (0.91) and [80-90] (0.87)\n",
    "    # It is lower in [50-60] (0.7) and [60-70] (0.73)\n",
    "\n",
    "# Flag rate varies a lot by age, up to about 77%, meaning operational burden is not uniform across subgroups.\n",
    "    # Extremely low in [0–10) (0.03), but that band is tiny and has zero positives\n",
    "    # It is low-ish in [50–60) (0.47) and [30–40) / [40–50) (~0.54–0.56)\n",
    "\t# High in [60–70) (0.61), [70–80) (0.69), [80–90) (0.77)\n",
    "        # The older groups are getting flagged moer frequently, and can be because of their feature patterns increasing the predicted risk, their base rates differ, etc.\n",
    "\n",
    "# PR-AUC is the highest for [20-30] and then drops towards older bands, in the range of about 0.17-0.28.\n",
    "    # This vary may be because of the base rate effect, pos_rate (being sensitive to the positive rate), and/or the model ranks better in some bands than others.\n",
    "\n",
    "# The plots visualize the same patterns: recall fluctuates across age bands, precision stays low, and PR-AUC declines with age.\n",
    "\n",
    "# For deployment, the model may over-flag older patients to maintain recall, while providing more targeted risk stratification for younger adults.\n",
    "# This motivates: \n",
    "    # age-aware calibration/thresholding\n",
    "    # choosing a threshold based on operational capacity and then checking subgroup impacts.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
